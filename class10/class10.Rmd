---
title: "class10"
author: "Kendall Lin"
date: "2/6/2020"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

##PCA issue -> SCALING
- the units measured will skew data because largest numbers will be given highest priority 
- Can fix this issue by using prcomp(x, scale = TRUE)

```{r}
wisc.df <- read.csv("data/WisconsinCancer.csv")
#there are funky things in this dataset that we will ignore for our analysis, this includes the first and second ID and diagnosis columns and the last X column -> wand columns 3 to 32
wisc.data <- as.matrix(wisc.df[,3:32])
row.names(wisc.data) <- wisc.df$id

#How many patients do we have data for? 
nrow(wisc.data)

#How many cancer/non-cancer?
table(wisc.df$diagnosis)
```


```{r}
#How many variables/features in the data are suffixed with _mean?
grep("_mean", colnames(wisc.data), value = T) # value = T tells you what the matches are and Value = F tells where they are
grep("_mean", colnames(wisc.data))

#How do i print out the sum of grep instaed of the position?
length(grep("_mean", colnames(wisc.data)))
```



##Principal Component Analysis

Before we turn to PCA we need to think, or consider, whether we should SCALE our input.

The input variables use different units of measurement.

- The input variables have significantly different variances.
- Check the mean and standard deviation of the features (i.e. columns) of the wisc.data to determine if the data should be scaled. Use the `colMeans()` and `apply()` functions like you’ve done before.


```{r}
round(apply(wisc.data, 2, sd), 2)
as.matrix(colMeans(wisc.data))
```

Looks like we need to set scale = TRUE!

```{r}
# Perform PCA on wisc.data by completing the following code
wisc.pr <- prcomp(wisc.data, scale = T)
summary(wisc.pr)

```


Q. From your results, what proportion of the original variance is captured by the first principal components (PC1)?

The 1st PC captures 44.27% of the original variance. Note that 72.6% is captured in the first 3 PCs..

Lets make some figures...

```{r}
biplot(wisc.pr)
```
That is a hot mess! We need to do our own PC1 vs PC2 plot and lets color by the diagnosis
```{r}
attributes(wisc.pr)
```

```{r}
# Scatter plot observations by components 1 and 2
diagnosis <- wisc.df$diagnosis
plot(wisc.pr$x[,1:2] , col = diagnosis, 
     xlab = "PC1", ylab = "PC2")
abline(h=0, col = "gray" , lty =2)
abline(v=0, col = "gray", lty = 2)
```

```{r}
# Repeat for components 1 and 3
plot(wisc.pr$x[,1], wisc.pr$x[,3],  col = diagnosis, 
     xlab = "PC1", ylab = "PC3")
```

```{r}
# Calculate variance of each component
pr.var <- wisc.pr$sdev^2
head(pr.var)
```

```{r}
# Variance explained by each principal component: pve
pve <- pr.var / sum(pr.var)

# Plot variance explained for each principal component
plot(pve, xlab = "Principal Component", 
     ylab = "Proportion of Variance Explained", 
     ylim = c(0, 1), type = "o")
```

```{r}
# Alternative scree plot of the same data, note data driven y-axis
barplot(pve, ylab = "Precent of Variance Explained",
     names.arg=paste0("PC",1:length(pve)), las=2, axes = FALSE)
axis(2, at=pve, labels=round(pve,2)*100 )
```

```{r}
## ggplot based graph
#install.packages("factoextra")
```
```{r}
library(factoextra)
fviz_eig(wisc.pr, addlabels = TRUE)
```


Kmeans
-> Kmeans(x, centers = 2, nstart = 20)
-> hclust(c)


Hierarchical clustering of case data

Plotting with raw data -> its a mess
```{r}
plot(hclust(dist(wisc.data)))
```

How about plot with scaling?
```{r}
# Scale the wisc.data data: data.scaled
data.scaled <- scale(wisc.data)
data.dist <- dist(data.scaled)
wisc.hclust <- hclust(data.dist, "complete")
plot(wisc.hclust)
abline(h= 18, col="red", lty=2)
```

Now with PCA data
##Clustering on PCA data
Let’s see if PCA improves or degrades the performance of hierarchical clustering.

Using the minimum number of principal components required to describe at least 90% of the variability in the data, create a hierarchical clustering model with the linkage method="ward.D2". We use Ward’s criterion here because it is based on multidimensional variance like principal components analysis. Assign the results to wisc.pr.hclust.

```{r}
wisc.pr.hclust <- hclust(dist(wisc.pr$x[,1:3]), method = "ward.D2")
plot(wisc.pr.hclust)

#use cutree() to figure out how many groups you want to cut the tree into -> you can cut at a height with h=_ or cut into a specified number of groups with k = _
grps <- cutree(wisc.pr.hclust, k=2)
table(grps)
```

We can use the `table()` function to compare the $diagnosis vector with out cluster results vector

```{r}
table(grps, diagnosis)
```

```{r}
plot(wisc.pr$x[,1:2], col=grps)
```

```{r}
g <- as.factor(grps)
levels(g)
g <- relevel(g,2)
levels(g)
plot(wisc.pr$x[,1:2], col=g)
```



##Prediction
We will use the predict() function that will take our PCA model from before and new cancer cell data and project that data onto our PCA space.

```{r}
#url <- "new_samples.csv"
url <- "https://tinyurl.com/new-samples-CSV"
new <- read.csv(url)
npc <- predict(wisc.pr, newdata=new)
npc
```

```{r}
plot(wisc.pr$x[,1:2], col=g)
points(npc[,1], npc[,2], col="blue", pch=16, cex=3)
text(npc[,1], npc[,2], c(1,2), col="white")
```





